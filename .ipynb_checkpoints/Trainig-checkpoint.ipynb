{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as  pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,recall_score,precision_score,f1_score\n",
    "import sys\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showMetrics(y_test,y_predictied):\n",
    "    conMat=confusion_matrix(y_test,y_predictied)\n",
    "    TP=conMat[1,1]\n",
    "    TN=conMat[0,0]\n",
    "    FP=conMat[0,1]\n",
    "    FN=conMat[1,0]\n",
    "    print (\"-\"*40)\n",
    "    print (\"Model Scores\")\n",
    "    print (\"TotalNumber of tests\",conMat.sum())\n",
    "    print (\"TP\",TP)\n",
    "    print (\"TN\",TN)\n",
    "    print (\"FP\",FP)\n",
    "    print (\"FN\",FN)\n",
    "\n",
    "    print (\"Accuracy :\",accuracy_score(y_test,y_predictied))\n",
    "\n",
    "    print (\"\\n\\n*** Positive class - majority in training *** \")\n",
    "    print (\"Recall_True Posiive Rate :\",recall_score(y_test,y_predictied)) # (TP/(TP+FN))\n",
    "    print (\"Precision_True Positive Rate :\",precision_score(y_test,y_predictied)) #(TP/(Tp+FP))\n",
    "    f1Positive=f1_score(y_test,y_predictied)\n",
    "    print(  \"F1 positive :\",f1_score(y_test,y_predictied))\n",
    "    \n",
    "    \n",
    "    print (\"\\n\\n*** Negative class - minority in training *** \")\n",
    "    RecallNegative=(TN/(TN+FP))\n",
    "    print (\"Recall_True Negative Rate :(TN/(TN+FP)) \",RecallNegative) # (TN/(TN+FP))\n",
    "    precisionNegative=(TN/(TN+FN))\n",
    "    print (\"Precision_True Negative Rate : # (TN/(TN+FN))\",precisionNegative)  # (TN/(TN+FN))\n",
    "    f1Negative=2*((RecallNegative*precisionNegative)/(RecallNegative+precisionNegative))\n",
    "    print(  \"F1 Negative :\", f1Negative  )\n",
    "    \n",
    "    print (    \"\\n\\n\\n ******************** Avg F1 score\",  (f1Positive+f1Negative)/2,'    **************************')\n",
    "    print (\"-\"*40)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***** ***** ****** *****\n",
    "# Steps\n",
    "# ***** ***** ****** *****\n",
    "\n",
    "- Loading the data\n",
    "- Splitting the data to x_train , y_train , x_test , y_test\n",
    "- Data Normalization\n",
    "- PCA and thats for two reason\n",
    "   - PCA can be used to reduce dimensios but in case of our data it isn't problem (because after doing OneHotEncodeing the number of columns is 43 so it is not large number)\n",
    "   - So i used PCA to reduce noise in the data by focusing on Princdipale components and remove components with low varaince (this in some cases can decrease accuracy because we lose some information but in our case accuracy have been improved ) \n",
    "- Use Support Vector Machine as the classifier (SVM)\n",
    "  - USe gaussian as the kernel because i think the data can be non linear separble \n",
    "  - choose class:weight 0 to be 2 to give more importance to minority class to try also reduce the effect of data imbalancing\n",
    "  - using grid search technique try to search for best combinatio of c and gamma parameters of SVM and with some hand searching i choosed gamma = 0.0004 and c=0.1 (meaning of these values that  that i want the model to give the priority to choose good hyperplane rather than classify correctly on train data (beacuase i belive have large noise))\n",
    "- ## Performance Criteria\n",
    "  - To judge the classifier i will not take into account accuracy because it can be misleading because the data is unbalanced i will compute f1 scores (because f1 score take into account recall and precision for specific class ) for both classes and take the average and this is my performance criteria \n",
    "  \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"training_processed.csv\",sep=';')\n",
    "test = pd.read_csv(\"validation_processed.csv\",sep=';')\n",
    "\n",
    "train.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "test.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable2</th>\n",
       "      <th>variable3</th>\n",
       "      <th>variable8</th>\n",
       "      <th>variable11</th>\n",
       "      <th>variable14</th>\n",
       "      <th>variable15</th>\n",
       "      <th>variable1_0</th>\n",
       "      <th>variable1_1</th>\n",
       "      <th>variable4_0</th>\n",
       "      <th>variable4_1</th>\n",
       "      <th>...</th>\n",
       "      <th>variable7_8</th>\n",
       "      <th>variable9_0</th>\n",
       "      <th>variable9_1</th>\n",
       "      <th>variable10_0</th>\n",
       "      <th>variable10_1</th>\n",
       "      <th>variable12_0</th>\n",
       "      <th>variable12_1</th>\n",
       "      <th>variable13_0</th>\n",
       "      <th>variable13_1</th>\n",
       "      <th>variable13_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.92</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>1.750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.92</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.25</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.17</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.33</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   variable2  variable3  variable8  variable11  variable14  variable15  \\\n",
       "0      17.92   0.000054      1.750         1.0        80.0         5.0   \n",
       "1      16.92   0.000034      0.290         0.0       200.0         0.0   \n",
       "2      31.25   0.000112      0.000         1.0        96.0        19.0   \n",
       "3      48.17   0.000133      0.335         0.0         0.0       120.0   \n",
       "4      32.33   0.000350      0.500         0.0       232.0         0.0   \n",
       "\n",
       "   variable1_0  variable1_1  variable4_0  variable4_1      ...       \\\n",
       "0          1.0          0.0          0.0          1.0      ...        \n",
       "1          0.0          1.0          0.0          0.0      ...        \n",
       "2          0.0          1.0          0.0          1.0      ...        \n",
       "3          1.0          0.0          0.0          1.0      ...        \n",
       "4          0.0          1.0          0.0          1.0      ...        \n",
       "\n",
       "   variable7_8  variable9_0  variable9_1  variable10_0  variable10_1  \\\n",
       "0          0.0          1.0          0.0           0.0           1.0   \n",
       "1          0.0          1.0          0.0           1.0           0.0   \n",
       "2          0.0          1.0          0.0           0.0           1.0   \n",
       "3          0.0          1.0          0.0           1.0           0.0   \n",
       "4          0.0          1.0          0.0           1.0           0.0   \n",
       "\n",
       "   variable12_0  variable12_1  variable13_0  variable13_1  variable13_2  \n",
       "0           0.0           1.0           1.0           0.0           0.0  \n",
       "1           1.0           0.0           0.0           0.0           1.0  \n",
       "2           1.0           0.0           1.0           0.0           0.0  \n",
       "3           1.0           0.0           1.0           0.0           0.0  \n",
       "4           0.0           1.0           1.0           0.0           0.0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## data splitting \n",
    "\n",
    "x_train=train.drop(\"classLabel\",axis=1)\n",
    "y_train=train[\"classLabel\"]\n",
    "\n",
    "x_test=test.drop(\"classLabel\",axis=1)\n",
    "y_test=test[\"classLabel\"]\n",
    "\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramym\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.19804502e+00, -9.32922311e-01, -1.86173583e-01, ...,\n",
       "         3.31913453e-01, -1.21361807e-01, -3.04741530e-01],\n",
       "       [-1.28585921e+00, -9.75798843e-01, -5.96345844e-01, ...,\n",
       "        -3.59747012e+00, -1.21361807e-01,  4.00987577e+00],\n",
       "       [-2.74818101e-02, -8.10567328e-01, -6.77818417e-01, ...,\n",
       "         3.31913453e-01, -1.21361807e-01, -3.04741530e-01],\n",
       "       ...,\n",
       "       [ 4.66650739e-04,  8.05463847e-01, -4.68791198e-01, ...,\n",
       "         3.31913453e-01, -1.21361807e-01, -3.04741530e-01],\n",
       "       [-4.53506090e-02, -8.39157418e-01, -6.40761498e-01, ...,\n",
       "         3.31913453e-01, -1.21361807e-01, -3.04741530e-01],\n",
       "       [-9.55727912e-01,  8.58211139e-02, -5.64476808e-01, ...,\n",
       "        -5.82381190e-01, -1.21361807e-01,  6.99189851e-01]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Fit on training set only.\n",
    "scaler.fit(x_train)\n",
    "# Apply transform to both the training set and the test set.\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "x_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(27)                              # choosing by experiement\n",
    "pca.fit(x_train)\n",
    "\n",
    "x_train = pca.transform(x_train)\n",
    "x_test = pca.transform(x_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn.svm import SVC # \"Support Vector Classifier\" \\n\\nparameter_candidates = [\\n  {\\'C\\': [1, 10, 100, 1000,1000], \\'gamma\\': [0.001, 0.0004,0.00001], \\'kernel\\': [\\'rbf\\']},\\n]\\n\\n# Create a classifier object with the classifier and parameter candidates\\nclf = GridSearchCV(estimator=SVC(class_weight={0:2}), param_grid=parameter_candidates, n_jobs=-1,verbose=10)\\n\\n# Train the classifier on data1\\'s feature and target data\\nclf.fit(x_train, y_train)   \\nprint(\\'Best score for data1:\\', clf.best_score_) \\nclf.best_estimator_\\n\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC # \"Support Vector Classifier\" \n",
    "\n",
    "parameter_candidates = [\n",
    "  {'C': [1, 10, 100, 1000,1000], 'gamma': [0.001, 0.0004,0.00001], 'kernel': ['rbf']},\n",
    "]\n",
    "\n",
    "# Create a classifier object with the classifier and parameter candidates\n",
    "clf = GridSearchCV(estimator=SVC(class_weight={0:2}), param_grid=parameter_candidates, n_jobs=-1,verbose=10)\n",
    "\n",
    "# Train the classifier on data1's feature and target data\n",
    "clf.fit(x_train, y_train)   \n",
    "print('Best score for data1:', clf.best_score_) \n",
    "clf.best_estimator_\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, cache_size=200, class_weight={0: 2}, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.0004, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=1e-09, verbose=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC # \"Support Vector Classifier\" \n",
    "clf = SVC(kernel='rbf', class_weight={0:2},gamma=0.0004,C=0.1,tol=1e-9) \n",
    "#clf = SVC(kernel='rbf', class_weight={0:2},C=2000) \n",
    "      \n",
    "# fitting x samples and y classes \n",
    "clf.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predictied=clf.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Model Scores\n",
      "TotalNumber of tests 200\n",
      "TP 83\n",
      "TN 95\n",
      "FP 12\n",
      "FN 10\n",
      "Accuracy : 0.89\n",
      "\n",
      "\n",
      "*** Positive class - majority in training *** \n",
      "Recall_True Posiive Rate : 0.8924731182795699\n",
      "Precision_True Positive Rate : 0.8736842105263158\n",
      "F1 positive : 0.8829787234042553\n",
      "\n",
      "\n",
      "*** Negative class - minority in training *** \n",
      "Recall_True Negative Rate :(TN/(TN+FP))  0.8878504672897196\n",
      "Precision_True Negative Rate : # (TN/(TN+FN)) 0.9047619047619048\n",
      "F1 Negative : 0.8962264150943396\n",
      "\n",
      "\n",
      "\n",
      " Avg F1 score 0.8896025692492975\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "showMetrics(y_test,y_predictied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
